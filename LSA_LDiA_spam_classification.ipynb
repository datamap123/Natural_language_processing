{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook a classification of spam and ham sms is performed with LDA, LSA and LDiA.\n",
    "\n",
    "The dataset is obtained from here: https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection\n",
    "\n",
    "The guidance how to do this kind of text classification is taken from book: Natural language processing in Action: Understanding, Analyzing and Generating Text with Python by Hobson Lane, Cole Howard, Hannes Max Hapke."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook text classification is performed for 'SMS Spam Collection Data Set'-dataset . The dataset can be found here: https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection\n",
    "\n",
    "Source of the data (2012):\n",
    "\n",
    "Tiago A. Almeida (talmeida ufscar.br) \n",
    "Department of Computer Science \n",
    "Federal University of Sao Carlos (UFSCar) \n",
    "Sorocaba, Sao Paulo - Brazil \n",
    "\n",
    "Attribute Information: The collection is composed by one text file, where each line has the correct class followed by the raw message. \n",
    "\n",
    "Relevant papers: Almeida, T.A., GÃ³mez Hidalgo, J.M., Yamakami, A. Contributions to the Study of SMS Spam Filtering: New Collection and Results. Proceedings of the 2011 ACM Symposium on Document Engineering (DOCENG'11), Mountain View, CA, USA, 2011."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.tokenize.casual import casual_tokenize\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDiA\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SMSSpamCollection') as f:\n",
    "    content =f.read() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam=[]; text=[]; index=[]\n",
    "for i, sent in enumerate(content.splitlines()):\n",
    "    line=sent.split('\\t')\n",
    "    spam.append(int(line[0]!='ham'))\n",
    "    text.append(line[1])\n",
    "    index.append('sms{}{}'.format(i,'!'*spam[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sms0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms2!</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       spam                                               text\n",
       "sms0      0  Go until jurong point, crazy.. Available only ...\n",
       "sms1      0                      Ok lar... Joking wif u oni...\n",
       "sms2!     1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "sms3      0  U dun say so early hor... U c already then say...\n",
       "sms4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'spam':spam,'text':text},index=index)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5574"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of document rows\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(747, 0.13)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of document rows that are spam, and the share of spam\n",
    "df.spam.sum(), round(df.spam.sum()/len(df),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus 13 % of the sms documents are spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Tf-Idf vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5574, 9232)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's do tokenization and TF-IDF vector transformation on all sms messages\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize.casual import casual_tokenize\n",
    "tfidf_model=TfidfVectorizer(tokenizer=casual_tokenize)\n",
    "tfidf_docs=tfidf_model.fit_transform(raw_documents=df.text).toarray()\n",
    "tfidf_docs=tfidf_docs-tfidf_docs.mean(axis=0)\n",
    "# rows: number of documents,columns:number of terms\n",
    "tfidf_docs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of spam messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to try simple LDA classification just with Tf-idf vectors, and compare that with cases where LDA is performed with topic vectors. In the latter case the topic vectors are created either with Latent Semantic Analysis, LSA (PCA), or Latent Dirichlet Allocation, LDiA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDiA\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import casual_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) LDA classification with Tf-idf vectors (no PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 0.748)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(tfidf_docs,df.spam.values,test_size=0.33,\n",
    "                                               random_state=256242)\n",
    "lda=LDA(n_components=1)\n",
    "lda=lda.fit(X_train,y_train)\n",
    "# accuracy for train and test sets\n",
    "round(float(lda.score(X_train,y_train)),3),   round(float(lda.score(X_test,y_test)),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training set accuracy is perfect, but test set accuracy is quite bad. It is thus better to use some method that reduces the number of dimensions. Let's try PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) LDA classification with 16 PCA topic vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>topic10</th>\n",
       "      <th>topic11</th>\n",
       "      <th>topic12</th>\n",
       "      <th>topic13</th>\n",
       "      <th>topic14</th>\n",
       "      <th>topic15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sms0</th>\n",
       "      <td>0.201</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms1</th>\n",
       "      <td>0.399</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>0.085</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.073</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms2!</th>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.055</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms3</th>\n",
       "      <td>0.326</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>0.055</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.122</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.086</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms5!</th>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.055</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.138</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.029</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       topic0  topic1  topic2  topic3  topic4  topic5  topic6  topic7  topic8  topic9  topic10  topic11  topic12  \\\n",
       "sms0    0.201   0.032   0.006  -0.004   0.019  -0.052   0.041  -0.046   0.012  -0.085   -0.000   -0.003   -0.001   \n",
       "sms1    0.399  -0.037  -0.078   0.085  -0.110   0.055   0.031   0.073  -0.017  -0.020    0.001    0.037   -0.030   \n",
       "sms2!  -0.029   0.055  -0.050  -0.102  -0.087  -0.040   0.004  -0.032  -0.029   0.070    0.116    0.033   -0.025   \n",
       "sms3    0.326  -0.034  -0.028   0.012  -0.055   0.055  -0.166  -0.024   0.050  -0.122    0.024    0.044   -0.079   \n",
       "sms4    0.003   0.035   0.030   0.015   0.070  -0.102  -0.036   0.034  -0.051   0.050    0.025    0.003   -0.005   \n",
       "sms5!  -0.021  -0.002   0.055  -0.028  -0.117  -0.042   0.019   0.138  -0.060   0.105    0.036    0.044    0.066   \n",
       "\n",
       "       topic13  topic14  topic15  \n",
       "sms0     0.021   -0.016   -0.036  \n",
       "sms1    -0.036    0.061    0.023  \n",
       "sms2!    0.035   -0.035   -0.044  \n",
       "sms3     0.003    0.042    0.025  \n",
       "sms4     0.086   -0.033    0.044  \n",
       "sms5!    0.029   -0.001   -0.005  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try PCA from scikit-learn, transforming 9232 dimension TF-IDF vectors into 16-D topic vectors\n",
    "pca=PCA(n_components=16)\n",
    "pca=pca.fit(tfidf_docs)\n",
    "pca_topic_vectors=pca.transform(tfidf_docs)\n",
    "columns=['topic{}'.format(i) for i in range(pca.n_components)]\n",
    "pca_topic_vectors=pd.DataFrame(pca_topic_vectors,columns=columns,index=index)\n",
    "pca_topic_vectors.round(3).head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use PCA topic vectors to train LDA model (simple binary classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.958, 0.959)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(pca_topic_vectors,df.spam,test_size=0.33,\n",
    "                                               random_state=256242)\n",
    "lda=LDA(n_components=1)\n",
    "lda=lda.fit(X_train,y_train)\n",
    "df['pca_spam']=lda.predict(pca_topic_vectors)\n",
    "# accuracy for train and test sets\n",
    "round(float(lda.score(X_train,y_train)),3),   round(float(lda.score(X_test,y_test)),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) LDA classification with 16 LDiA topic vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>\"</th>\n",
       "      <th>#</th>\n",
       "      <th>#150</th>\n",
       "      <th>#5000</th>\n",
       "      <th>$</th>\n",
       "      <th>%</th>\n",
       "      <th>&amp;</th>\n",
       "      <th>'</th>\n",
       "      <th>(</th>\n",
       "      <th>...</th>\n",
       "      <th>ü'll</th>\n",
       "      <th>–</th>\n",
       "      <th>—</th>\n",
       "      <th>‘</th>\n",
       "      <th>’</th>\n",
       "      <th>“</th>\n",
       "      <th>…</th>\n",
       "      <th>┾</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>鈥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sms0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms2!</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9232 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       !  \"  #  #150  #5000  $  %  &  '  (  ...  ü'll  –  —  ‘  ’  “  …  ┾  〨ud  鈥\n",
       "sms0   0  0  0     0      0  0  0  0  0  0  ...     0  0  0  0  0  0  0  0    0  0\n",
       "sms1   0  0  0     0      0  0  0  0  0  0  ...     0  0  0  0  0  0  0  0    0  0\n",
       "sms2!  0  0  0     0      0  0  0  1  1  1  ...     0  0  0  0  0  0  0  0    0  0\n",
       "sms3   0  0  0     0      0  0  0  0  0  0  ...     0  0  0  0  0  0  0  0    0  0\n",
       "sms4   0  0  0     0      0  0  0  0  0  0  ...     0  0  0  0  0  0  0  0    0  0\n",
       "\n",
       "[5 rows x 9232 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDiA works with raw BOW count vectors rather than normalized TF-IDF vectors\n",
    "np.random.seed(42)\n",
    "counter=CountVectorizer(tokenizer=casual_tokenize)\n",
    "bow_docs=pd.DataFrame(counter.fit_transform(raw_documents=df.text).toarray(),index=index)\n",
    "column_nums,terms=zip(*sorted(zip(counter.vocabulary_.values(),counter.vocabulary_.keys())))\n",
    "bow_docs.columns=terms\n",
    "bow_docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 9232)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the ldia model\n",
    "ldia=LDiA(n_components=16,learning_method='batch')\n",
    "ldia=ldia.fit(bow_docs)\n",
    "# rows: 16 topics, columns: 9232 terms\n",
    "ldia.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>topic10</th>\n",
       "      <th>topic11</th>\n",
       "      <th>topic12</th>\n",
       "      <th>topic13</th>\n",
       "      <th>topic14</th>\n",
       "      <th>topic15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sms0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms2!</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       topic0  topic1  topic2  topic3  topic4  topic5  \\\n",
       "sms0     0.00    0.44    0.00    0.00    0.00    0.00   \n",
       "sms1     0.01    0.01    0.01    0.01    0.01    0.01   \n",
       "sms2!    0.00    0.00    0.00    0.00    0.00    0.00   \n",
       "sms3     0.00    0.00    0.00    0.11    0.00    0.00   \n",
       "sms4     0.54    0.00    0.32    0.00    0.00    0.00   \n",
       "\n",
       "       topic6  topic7  topic8  topic9  topic10  topic11  \\\n",
       "sms0     0.00    0.00    0.53    0.00     0.00     0.00   \n",
       "sms1     0.01    0.01    0.67    0.01     0.01     0.24   \n",
       "sms2!    0.00    0.00    0.00    0.00     0.39     0.27   \n",
       "sms3     0.00    0.00    0.83    0.00     0.00     0.00   \n",
       "sms4     0.00    0.00    0.00    0.00     0.00     0.08   \n",
       "\n",
       "       topic12  topic13  topic14  topic15  \n",
       "sms0      0.00     0.00     0.00     0.00  \n",
       "sms1      0.01     0.01     0.01     0.01  \n",
       "sms2!     0.00     0.00     0.31     0.00  \n",
       "sms3      0.00     0.00     0.00     0.00  \n",
       "sms4      0.00     0.00     0.00     0.00  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then create topic vectors with LDiA for this sms corpus\n",
    "pd.set_option('display.width',60)\n",
    "ldia16_topic_vectors=ldia.transform(bow_docs)\n",
    "ldia16_topic_vectors=pd.DataFrame(ldia16_topic_vectors,index=index,columns=columns)\n",
    "ldia16_topic_vectors.round(2).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use LDiA topic vectors (created from BOW vectors) to train LDA model (simple binary classifier), in the similar way it was done with PCA topic vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.918, 0.92)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(ldia16_topic_vectors,df.spam,test_size=0.33,\n",
    "                                               random_state=256242)\n",
    "lda=LDA(n_components=1)\n",
    "lda=lda.fit(X_train,y_train)\n",
    "df['ldia16_spam']=lda.predict(ldia16_topic_vectors)\n",
    "\n",
    "# accuracy for train and test sets\n",
    "round(float(lda.score(X_train,y_train)),3),   round(float(lda.score(X_test,y_test)),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result was worse than with PCA topic vectors. Let's try LDiA with a bit larger number of topic vectors, 32."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) LDA classification with 32 LDiA topic vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDiA works in a bit different way as LSA (PCA) so it usually needs more topics to allocate words to. Let's try 32 topics (components) instead of 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 9232)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldia32=LDiA(n_components=32,learning_method='batch')\n",
    "ldia32=ldia32.fit(bow_docs)\n",
    "# Rows: 32 topics, columns: 9232 terms\n",
    "ldia32.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>...</th>\n",
       "      <th>topic22</th>\n",
       "      <th>topic23</th>\n",
       "      <th>topic24</th>\n",
       "      <th>topic25</th>\n",
       "      <th>topic26</th>\n",
       "      <th>topic27</th>\n",
       "      <th>topic28</th>\n",
       "      <th>topic29</th>\n",
       "      <th>topic30</th>\n",
       "      <th>topic31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sms0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms2!</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       topic0  topic1  topic2  topic3  topic4  topic5  \\\n",
       "sms0      0.0     0.0     0.0    0.00    0.00     0.0   \n",
       "sms1      0.0     0.0     0.0    0.00    0.25     0.0   \n",
       "sms2!     0.0     0.0     0.0    0.98    0.00     0.0   \n",
       "sms3      0.0     0.0     0.0    0.00    0.16     0.0   \n",
       "sms4      0.0     0.0     0.0    0.00    0.00     0.4   \n",
       "\n",
       "       topic6  topic7  topic8  topic9  ...  topic22  \\\n",
       "sms0      0.0     0.0    0.50     0.0  ...      0.0   \n",
       "sms1      0.0     0.0    0.51     0.0  ...      0.0   \n",
       "sms2!     0.0     0.0    0.00     0.0  ...      0.0   \n",
       "sms3      0.0     0.0    0.62     0.0  ...      0.0   \n",
       "sms4      0.0     0.0    0.00     0.0  ...      0.0   \n",
       "\n",
       "       topic23  topic24  topic25  topic26  topic27  \\\n",
       "sms0       0.0      0.0      0.0      0.0      0.0   \n",
       "sms1       0.0      0.0      0.0      0.0      0.0   \n",
       "sms2!      0.0      0.0      0.0      0.0      0.0   \n",
       "sms3       0.0      0.0      0.0      0.0      0.0   \n",
       "sms4       0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "       topic28  topic29  topic30  topic31  \n",
       "sms0       0.0      0.0      0.0      0.0  \n",
       "sms1       0.0      0.0      0.0      0.0  \n",
       "sms2!      0.0      0.0      0.0      0.0  \n",
       "sms3       0.0      0.0      0.0      0.0  \n",
       "sms4       0.0      0.0      0.0      0.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's compute 32-D topic vectors for all the sms messages\n",
    "ldia32_topic_vectors=ldia32.transform(bow_docs)\n",
    "columns32=['topic{}'.format(i) for i in range(ldia32.n_components)]\n",
    "ldia32_topic_vectors=pd.DataFrame(ldia32_topic_vectors,index=index,columns=columns32)\n",
    "ldia32_topic_vectors.round(2).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3734, 32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA model (classifier training)\n",
    "X_train,X_test,y_train,y_test=train_test_split(ldia32_topic_vectors,df.spam,test_size=0.33,\n",
    "                                               random_state=256242)\n",
    "lda=LDA(n_components=1)\n",
    "lda=lda.fit(X_train,y_train)\n",
    "df['ldia32_spam']=lda.predict(ldia32_topic_vectors)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.924, 0.922)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at accuracy for train and test set\n",
    "round(float(lda.score(X_train,y_train)),3),  round(float(lda.score(X_test,y_test)),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score didn't really improve very much, only slightly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook the spam classification was performed with four methods:\n",
    "- a) LDA classification done with Tf-idf vectors\n",
    "- b) LDA classification with 16 topic vectors created by LSA (PCA)\n",
    "- c) LDA classification with 16 topic vectors created by LDiA\n",
    "- d) LDA classification with 32 topic vectors created by LDiA\n",
    "\n",
    "The results show that some kind of dimension reduction method is needed, since a) gave poor results with test set. The best accuracy score was obtained with b) , when LSA, Latent semantic analysis with PCA was used for creating 16 topic vectors. LDA classification was then performed with these 16 topic vectors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
