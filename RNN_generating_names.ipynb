{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of RNN-task.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BTcHfB1njlS",
        "colab_type": "text"
      },
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkJgiyo5AjS7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "2d61218b-3ec7-4cad-c936-cb3760a0cfa8"
      },
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "# please, uncomment the week you're working on\n",
        "setup_google_colab.setup_week5()\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shred: setup_google_colab.py: failed to open for writing: No such file or directory\n",
            "--2019-05-10 13:50:35--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3792 (3.7K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "setup_google_colab. 100%[===================>]   3.70K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-05-10 13:50:35 (49.0 MB/s) - ‘setup_google_colab.py’ saved [3792/3792]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "id": "g1vBsSLanjl2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "47a23f46-78b9-45c8-d96e-8fa5bb2f10d2"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJwgsQwCnjm6",
        "colab_type": "text"
      },
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "id": "ZGKdwGRnnjnH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "id": "Me67gs88njnz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "e4e636d9-6714-4d81-8940-0acae6d947d3"
      },
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "id": "Kv8nZP9Pnjoj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "031a6083-58b6-4559-8f52-22e162dcdb86"
      },
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEICAYAAAC55kg0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAlKrRyInjpC",
        "colab_type": "text"
      },
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "id": "31Ue0QkunjpK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ac9d1b53-15d1-4d42-994e-167a37ba14f1"
      },
      "source": [
        "#tokens = ### YOUR CODE HERE: all unique characters go here, padding included!\n",
        "tokens=set()\n",
        "for name in names:\n",
        "  for character in name:\n",
        "    tokens.add(character)\n",
        "#tokens.add(start_token)\n",
        "tokens.add(pad_token)\n",
        "tokens = list(tokens)\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_tokens: 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tG2dH-9njpk",
        "colab_type": "text"
      },
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "id": "O9cnRGBvnjpu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#token_to_id = ### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
        "token_to_id={token:id for id, token in enumerate(tokens)}\n",
        "\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "id": "s7i8cy6XnjqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "id": "p3ih_MqBnjq3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "55255f69-5911-4790-d692-375567f63d61"
      },
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[ 7 52 10 53 26 53 11 42 39]\n",
            " [ 7 49 42 29 37 27 39 39 39]\n",
            " [ 7 13 37 47 46 46 47 11 39]\n",
            " [ 7 49 47 29 44 53 14 14 11]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEaWQDMNnjrh",
        "colab_type": "text"
      },
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "id": "QHxIvQ52njrx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "id": "xCNM2VVbnjsr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "#get_h_next = ### YOUR CODE HERE\n",
        "get_h_next=Dense(rnn_num_units,activation='tanh')\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "#get_probas = ### YOUR CODE HERE\n",
        "get_probas=Dense(n_tokens,activation='softmax')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0x6ory7CnjtB",
        "colab_type": "text"
      },
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "id": "kxj9X2l7njtI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    #x_and_h = ### YOUR CODE HERE\n",
        "    x_and_h=concatenate([x_t_emb,h_t])\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    #h_next = ### YOUR CODE HERE\n",
        "    h_next=get_h_next(x_and_h)\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    #output_probas = ### YOUR CODE HERE\n",
        "    output_probas=get_probas(h_next)\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdkbRrVqnjtq",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "id": "-UTUkShunjtx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yjx5Nok5njuL",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "id": "XSOom1j8njuV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ple2ju7onjuz",
        "colab_type": "text"
      },
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "id": "6YcbOrcrnju6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "#loss = ### YOUR CODE HERE\n",
        "\n",
        "loss=-tf.reduce_mean(answers_matrix*tf.log(predictions_matrix))\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eLm22XpnjvP",
        "colab_type": "text"
      },
      "source": [
        "# RNN: training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "id": "SEdAjLh4njvU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "adad021e-b50f-4cbe-ca6f-e3e44731dd25"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nr5RSceT/Af5L5XhQnkN3AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsM3wmfUnjwj",
        "colab_type": "text"
      },
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "id": "J1i--A56njwr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "id": "0b5k3gHCnjxA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "id": "qeXS6E-mnjxm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "44b7dd74-19cc-414c-fbdf-6797391bf1ae"
      },
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Eqtingy\n",
            " Narnlleona\n",
            " Clallit\n",
            " Andalte\n",
            " Mivia\n",
            " Jilostiso\n",
            " Kame\n",
            " Xeilie\n",
            " Celly\n",
            " Crusya\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "id": "N9uMeZr6njyK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "52b09b16-abd3-4365-ba2d-cba20f2bd8b0"
      },
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Trumpy\n",
            " Trumpen\n",
            " Trumpela\n",
            " Trumpa\n",
            " Trump\n",
            " Trumpie\n",
            " Trumpe\n",
            " Trumponls\n",
            " Trumpeda\n",
            " Trumpao\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPNSM04TnjzJ",
        "colab_type": "text"
      },
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "id": "-QkSqjr3njzT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"EQ7TaIu3pjX29SG2\"\n",
        "COURSERA_EMAIL = \"avi.mtere@gmail.com\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "id": "AOM91uGLnjzq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "3589806e-6041-40fe-b053-55879f53c442"
      },
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n",
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4zbWsIFnj0i",
        "colab_type": "text"
      },
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "v4QARKFbnj0q",
        "colab_type": "text"
      },
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "id": "Li_kLRqqnj0w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_bYp_o7nj1O",
        "colab_type": "text"
      },
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "id": "GvLglZvYnj1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "id": "n6OshWi2nj2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}