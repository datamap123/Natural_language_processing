{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment classification of sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook a classification of sentiment of sentences is performed with Linear Discriminant analysis (LDA), Latent Semantic Analysis (LSA) and Latent Dirichlet Allocation (LDiA).\n",
    "\n",
    "The dataset is obtained from here: https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source of the data (2015): Dimitrios Kotzias dkotzias '@' ics.uci.edu\n",
    "\n",
    "Dataset information:\n",
    "- contains sentences labelled with positive or negative sentiment. \n",
    "- format: sentence score, either 1 (for positive) or 0 (for negative) \n",
    "- The attributes are text sentences, extracted from reviews of products, movies, and restaurants\n",
    "- The sentences come from three different websites/fields:imdb.com,amazon.com,yelp.com \n",
    "\n",
    "For each website, there exist 500 positive and 500 negative sentences. Those were selected randomly for larger datasets of reviews. Sentences were selected so that they have a clearly positive or negative connotaton. Thus the goal was for no neutral sentences to be selected. \n",
    "\n",
    "Relevant papers: 'From Group to Individual Labels using Deep Features', Kotzias et. al,. KDD 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.tokenize.casual import casual_tokenize\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDiA\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('amazon_cells_labelled.txt') as f:\n",
    "    content =f.read() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=[]; text=[]; index=[]\n",
    "for i, sentence in enumerate(content.splitlines()):\n",
    "    line=sentence.split('\\t')\n",
    "    text.append(line[0])\n",
    "    score.append(int(line[1]=='1'))\n",
    "    index.append('sent{}'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('yelp_labelled.txt') as f:\n",
    "    content =f.read() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_length=len(text)\n",
    "for i, sentence in enumerate(content.splitlines()):\n",
    "    line=sentence.split('\\t')\n",
    "    text.append(line[0])\n",
    "    score.append(int(line[1]=='1'))\n",
    "    index.append('sent{}'.format(i+prev_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('imdb_labelled.txt') as f:\n",
    "    content =f.read() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_length=len(text)\n",
    "j=0\n",
    "for i, sentence in enumerate(content.splitlines()):\n",
    "    line=sentence.split('\\t')        \n",
    "    if len(line)==2:\n",
    "        text.append(line[0])\n",
    "        score.append(int(line[1]=='1'))\n",
    "        index.append('sent{}'.format(j+prev_length))\n",
    "        j+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sent0</th>\n",
       "      <td>0</td>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent1</th>\n",
       "      <td>1</td>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent2</th>\n",
       "      <td>1</td>\n",
       "      <td>Great for the jawbone.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent3</th>\n",
       "      <td>0</td>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent4</th>\n",
       "      <td>1</td>\n",
       "      <td>The mic is great.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       score                                               text\n",
       "sent0      0  So there is no way for me to plug it in here i...\n",
       "sent1      1                        Good case, Excellent value.\n",
       "sent2      1                             Great for the jawbone.\n",
       "sent3      0  Tied to charger for conversations lasting more...\n",
       "sent4      1                                  The mic is great."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'score':score,'text':text},index=index)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sent2995</th>\n",
       "      <td>0</td>\n",
       "      <td>I just got bored watching Jessice Lange take h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent2996</th>\n",
       "      <td>0</td>\n",
       "      <td>Unfortunately, any virtue in this film's produ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent2997</th>\n",
       "      <td>0</td>\n",
       "      <td>In a word, it is embarrassing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent2998</th>\n",
       "      <td>0</td>\n",
       "      <td>Exceptionally bad!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent2999</th>\n",
       "      <td>0</td>\n",
       "      <td>All in all its an insult to one's intelligence...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          score                                               text\n",
       "sent2995      0  I just got bored watching Jessice Lange take h...\n",
       "sent2996      0  Unfortunately, any virtue in this film's produ...\n",
       "sent2997      0                   In a word, it is embarrassing.  \n",
       "sent2998      0                               Exceptionally bad!  \n",
       "sent2999      0  All in all its an insult to one's intelligence..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of document rows\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 0.5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of document rows that are positive, and the share of classes\n",
    "df.score.sum(), round(df.score.sum()/len(df),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus the dataset is balanced, 50 % of the sentences are positive, 50% negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Tf-Idf vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 5399)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's do tokenization and TF-IDF vector transformation on all sentences\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize.casual import casual_tokenize\n",
    "tfidf_model=TfidfVectorizer(tokenizer=casual_tokenize)\n",
    "tfidf_docs=tfidf_model.fit_transform(raw_documents=df.text).toarray()\n",
    "tfidf_docs=tfidf_docs-tfidf_docs.mean(axis=0)\n",
    "# rows: number of documents,columns:number of terms\n",
    "tfidf_docs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment classification  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to try simple LDA classification just with Tf-idf vectors, and compare that with cases where LDA is performed with topic vectors. In the latter case the topic vectors are created either with Latent Semantic Analysis, LSA (PCA), or Latent Dirichlet Allocation, LDiA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDiA\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import casual_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) LDA classification with Tf-idf vectors (no PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 0.682)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(tfidf_docs,df.score.values,test_size=0.33,\n",
    "                                               random_state=256242)\n",
    "lda=LDA(n_components=1)\n",
    "lda=lda.fit(X_train,y_train)\n",
    "# accuracy for train and test sets\n",
    "round(float(lda.score(X_train,y_train)),3),   round(float(lda.score(X_test,y_test)),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training set accuracy is perfect, but test set accuracy is quite bad. It is thus better to use some method that reduces the number of dimensions. Let's try PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) LDA classification and LSA with 256 PCA topic vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>...</th>\n",
       "      <th>topic246</th>\n",
       "      <th>topic247</th>\n",
       "      <th>topic248</th>\n",
       "      <th>topic249</th>\n",
       "      <th>topic250</th>\n",
       "      <th>topic251</th>\n",
       "      <th>topic252</th>\n",
       "      <th>topic253</th>\n",
       "      <th>topic254</th>\n",
       "      <th>topic255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sent0</th>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.224</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent2</th>\n",
       "      <td>0.063</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.192</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.081</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent3</th>\n",
       "      <td>0.246</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent4</th>\n",
       "      <td>0.053</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.145</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.177</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent5</th>\n",
       "      <td>-0.062</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.026</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       topic0  topic1  topic2  topic3  topic4  topic5  topic6  topic7  topic8  \\\n",
       "sent0  -0.061  -0.099   0.013  -0.039   0.032  -0.079  -0.049  -0.004   0.033   \n",
       "sent1   0.010   0.102   0.016   0.075   0.091   0.224  -0.135   0.129   0.068   \n",
       "sent2   0.063   0.169   0.139   0.192  -0.113  -0.166   0.022   0.087   0.081   \n",
       "sent3   0.246  -0.027  -0.043  -0.097  -0.044  -0.005  -0.048  -0.010   0.013   \n",
       "sent4   0.053   0.215   0.252   0.145  -0.007  -0.149   0.092   0.020   0.177   \n",
       "sent5  -0.062  -0.134  -0.064  -0.018  -0.051  -0.083  -0.064  -0.022   0.103   \n",
       "\n",
       "       topic9  ...  topic246  topic247  topic248  topic249  topic250  \\\n",
       "sent0  -0.073  ...     0.040    -0.009     0.015    -0.007     0.002   \n",
       "sent1   0.004  ...     0.028    -0.004    -0.017     0.053    -0.078   \n",
       "sent2  -0.022  ...    -0.008    -0.016    -0.014    -0.004    -0.005   \n",
       "sent3   0.007  ...     0.028    -0.006    -0.017    -0.036    -0.007   \n",
       "sent4  -0.059  ...     0.006    -0.021    -0.012    -0.016    -0.033   \n",
       "sent5   0.026  ...    -0.011    -0.011    -0.009    -0.028    -0.006   \n",
       "\n",
       "       topic251  topic252  topic253  topic254  topic255  \n",
       "sent0     0.036    -0.024     0.015    -0.002    -0.015  \n",
       "sent1    -0.028    -0.020     0.077     0.047     0.005  \n",
       "sent2    -0.000     0.010     0.003     0.010     0.012  \n",
       "sent3    -0.024     0.011    -0.006    -0.008    -0.016  \n",
       "sent4    -0.012    -0.024    -0.017     0.028     0.022  \n",
       "sent5     0.027     0.010    -0.020     0.030    -0.008  \n",
       "\n",
       "[6 rows x 256 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try PCA from scikit-learn, transforming 5399 dimension TF-IDF vectors into 256-D topic vectors\n",
    "pca=PCA(n_components=256)\n",
    "pca=pca.fit(tfidf_docs)\n",
    "pca256_topic_vectors=pca.transform(tfidf_docs)\n",
    "columns256=['topic{}'.format(i) for i in range(pca.n_components)]\n",
    "pca256_topic_vectors=pd.DataFrame(pca256_topic_vectors,columns=columns256,index=index)\n",
    "pca256_topic_vectors.round(3).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.844, 0.776)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(pca256_topic_vectors,df.score,test_size=0.33,\n",
    "                                               random_state=256242)\n",
    "lda=LDA(n_components=1)\n",
    "lda=lda.fit(X_train,y_train)\n",
    "df['pca256_sentiment']=lda.predict(pca256_topic_vectors)\n",
    "# accuracy for train and test sets\n",
    "round(float(lda.score(X_train,y_train)),3),   round(float(lda.score(X_test,y_test)),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) LDA classification and LSA with 384 PCA topic vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>...</th>\n",
       "      <th>topic374</th>\n",
       "      <th>topic375</th>\n",
       "      <th>topic376</th>\n",
       "      <th>topic377</th>\n",
       "      <th>topic378</th>\n",
       "      <th>topic379</th>\n",
       "      <th>topic380</th>\n",
       "      <th>topic381</th>\n",
       "      <th>topic382</th>\n",
       "      <th>topic383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sent0</th>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.224</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.004</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent2</th>\n",
       "      <td>0.063</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.192</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.081</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>-0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent3</th>\n",
       "      <td>0.246</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent4</th>\n",
       "      <td>0.053</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.145</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.177</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent5</th>\n",
       "      <td>-0.062</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       topic0  topic1  topic2  topic3  topic4  topic5  topic6  topic7  topic8  \\\n",
       "sent0  -0.061  -0.099   0.013  -0.039   0.032  -0.079  -0.049  -0.004   0.033   \n",
       "sent1   0.010   0.102   0.016   0.075   0.091   0.224  -0.135   0.129   0.068   \n",
       "sent2   0.063   0.169   0.139   0.192  -0.113  -0.166   0.022   0.087   0.081   \n",
       "sent3   0.246  -0.027  -0.043  -0.097  -0.044  -0.005  -0.048  -0.010   0.013   \n",
       "sent4   0.053   0.215   0.252   0.145  -0.007  -0.149   0.092   0.020   0.177   \n",
       "sent5  -0.062  -0.134  -0.064  -0.018  -0.051  -0.083  -0.064  -0.022   0.103   \n",
       "\n",
       "       topic9  ...  topic374  topic375  topic376  topic377  topic378  \\\n",
       "sent0  -0.073  ...     0.017     0.015    -0.009    -0.003     0.041   \n",
       "sent1   0.004  ...    -0.003    -0.003     0.002    -0.007    -0.001   \n",
       "sent2  -0.022  ...     0.022    -0.036    -0.001     0.050     0.009   \n",
       "sent3   0.007  ...    -0.009     0.022    -0.005    -0.001    -0.017   \n",
       "sent4  -0.059  ...     0.040    -0.010    -0.009    -0.021    -0.003   \n",
       "sent5   0.026  ...     0.014     0.004    -0.038    -0.005     0.008   \n",
       "\n",
       "       topic379  topic380  topic381  topic382  topic383  \n",
       "sent0    -0.001     0.006    -0.039     0.019    -0.002  \n",
       "sent1    -0.001    -0.023     0.008     0.004     0.005  \n",
       "sent2    -0.023    -0.047     0.036    -0.085    -0.007  \n",
       "sent3     0.024    -0.007    -0.031    -0.016    -0.025  \n",
       "sent4    -0.033     0.052     0.009     0.001     0.014  \n",
       "sent5     0.002    -0.020    -0.004     0.007     0.014  \n",
       "\n",
       "[6 rows x 384 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try PCA from scikit-learn, transforming 5399 dimension TF-IDF vectors into 384-D topic vectors\n",
    "pca=PCA(n_components=384)\n",
    "pca=pca.fit(tfidf_docs)\n",
    "pca384_topic_vectors=pca.transform(tfidf_docs)\n",
    "columns384=['topic{}'.format(i) for i in range(pca.n_components)]\n",
    "pca384_topic_vectors=pd.DataFrame(pca384_topic_vectors,columns=columns384,index=index)\n",
    "pca384_topic_vectors.round(3).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.88, 0.8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(pca384_topic_vectors,df.score,test_size=0.33,\n",
    "                                               random_state=256242)\n",
    "lda=LDA(n_components=1)\n",
    "lda=lda.fit(X_train,y_train)\n",
    "df['pca384_sentiment']=lda.predict(pca384_topic_vectors)\n",
    "# accuracy for train and test sets\n",
    "round(float(lda.score(X_train,y_train)),3),   round(float(lda.score(X_test,y_test)),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) LDA classification and LSA with 312 PCA topic vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>...</th>\n",
       "      <th>topic302</th>\n",
       "      <th>topic303</th>\n",
       "      <th>topic304</th>\n",
       "      <th>topic305</th>\n",
       "      <th>topic306</th>\n",
       "      <th>topic307</th>\n",
       "      <th>topic308</th>\n",
       "      <th>topic309</th>\n",
       "      <th>topic310</th>\n",
       "      <th>topic311</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sent0</th>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.224</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent2</th>\n",
       "      <td>0.063</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.192</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.081</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent3</th>\n",
       "      <td>0.246</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent4</th>\n",
       "      <td>0.053</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.145</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.177</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent5</th>\n",
       "      <td>-0.062</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.026</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       topic0  topic1  topic2  topic3  topic4  topic5  topic6  topic7  topic8  \\\n",
       "sent0  -0.061  -0.099   0.013  -0.039   0.032  -0.079  -0.049  -0.004   0.033   \n",
       "sent1   0.010   0.102   0.016   0.075   0.091   0.224  -0.135   0.129   0.068   \n",
       "sent2   0.063   0.169   0.139   0.192  -0.113  -0.166   0.022   0.087   0.081   \n",
       "sent3   0.246  -0.027  -0.043  -0.097  -0.044  -0.005  -0.048  -0.010   0.013   \n",
       "sent4   0.053   0.215   0.252   0.145  -0.007  -0.149   0.092   0.020   0.177   \n",
       "sent5  -0.062  -0.134  -0.064  -0.018  -0.051  -0.083  -0.064  -0.022   0.103   \n",
       "\n",
       "       topic9  ...  topic302  topic303  topic304  topic305  topic306  \\\n",
       "sent0  -0.073  ...     0.035     0.040     0.005     0.001     0.003   \n",
       "sent1   0.004  ...     0.031    -0.031     0.006    -0.001    -0.001   \n",
       "sent2  -0.022  ...     0.008    -0.015    -0.000     0.001     0.010   \n",
       "sent3   0.007  ...     0.015    -0.007     0.034    -0.060    -0.019   \n",
       "sent4  -0.059  ...     0.004     0.016     0.035    -0.001     0.003   \n",
       "sent5   0.026  ...    -0.017     0.040    -0.034    -0.022     0.004   \n",
       "\n",
       "       topic307  topic308  topic309  topic310  topic311  \n",
       "sent0    -0.023    -0.026     0.023    -0.031     0.067  \n",
       "sent1     0.003    -0.018    -0.013    -0.028     0.007  \n",
       "sent2     0.027     0.000     0.009     0.013     0.005  \n",
       "sent3     0.029     0.014     0.015     0.027    -0.004  \n",
       "sent4    -0.025     0.032    -0.043    -0.024    -0.031  \n",
       "sent5     0.019     0.015    -0.012     0.001     0.045  \n",
       "\n",
       "[6 rows x 312 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try PCA from scikit-learn, transforming 5399 dimension TF-IDF vectors into 312-D topic vectors\n",
    "pca=PCA(n_components=312)\n",
    "pca=pca.fit(tfidf_docs)\n",
    "pca312_topic_vectors=pca.transform(tfidf_docs)\n",
    "columns312=['topic{}'.format(i) for i in range(pca.n_components)]\n",
    "pca312_topic_vectors=pd.DataFrame(pca312_topic_vectors,columns=columns312,index=index)\n",
    "pca312_topic_vectors.round(3).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.858, 0.789)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(pca312_topic_vectors,df.score,test_size=0.33,\n",
    "                                               random_state=256242)\n",
    "lda=LDA(n_components=1)\n",
    "lda=lda.fit(X_train,y_train)\n",
    "df['pca312_sentiment']=lda.predict(pca312_topic_vectors)\n",
    "# accuracy for train and test sets\n",
    "round(float(lda.score(X_train,y_train)),3),   round(float(lda.score(X_test,y_test)),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the score seems to be rather optimized vs. number of components. Let's still try LDA with LDiA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) LDA classification with 312 LDiA topic vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>\"</th>\n",
       "      <th>#</th>\n",
       "      <th>$</th>\n",
       "      <th>%</th>\n",
       "      <th>&amp;</th>\n",
       "      <th>'</th>\n",
       "      <th>(</th>\n",
       "      <th>(;</th>\n",
       "      <th>)</th>\n",
       "      <th>...</th>\n",
       "      <th>yun</th>\n",
       "      <th>z</th>\n",
       "      <th>z500a</th>\n",
       "      <th>zero</th>\n",
       "      <th>zillion</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombie-students</th>\n",
       "      <th>zombiez</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sent0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5399 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       !  \"  #  $  %  &  '  (  (;  )  ...  yun  z  z500a  zero  zillion  \\\n",
       "sent0  0  0  0  0  0  0  0  0   0  0  ...    0  0      0     0        0   \n",
       "sent1  0  0  0  0  0  0  0  0   0  0  ...    0  0      0     0        0   \n",
       "sent2  0  0  0  0  0  0  0  0   0  0  ...    0  0      0     0        0   \n",
       "sent3  2  0  0  0  0  0  0  0   0  0  ...    0  0      0     0        0   \n",
       "sent4  0  0  0  0  0  0  0  0   0  0  ...    0  0      0     0        0   \n",
       "\n",
       "       zombie  zombie-students  zombiez      \n",
       "sent0       0                0        0  0  0  \n",
       "sent1       0                0        0  0  0  \n",
       "sent2       0                0        0  0  0  \n",
       "sent3       0                0        0  0  0  \n",
       "sent4       0                0        0  0  0  \n",
       "\n",
       "[5 rows x 5399 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDiA works with raw BOW count vectors rather than normalized TF-IDF vectors\n",
    "np.random.seed(42)\n",
    "counter=CountVectorizer(tokenizer=casual_tokenize)\n",
    "bow_docs=pd.DataFrame(counter.fit_transform(raw_documents=df.text).toarray(),index=index)\n",
    "column_nums,terms=zip(*sorted(zip(counter.vocabulary_.values(),counter.vocabulary_.keys())))\n",
    "bow_docs.columns=terms\n",
    "bow_docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(312, 5399)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldia312=LDiA(n_components=312,learning_method='batch')\n",
    "ldia312=ldia312.fit(bow_docs)\n",
    "ldia312.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>...</th>\n",
       "      <th>topic302</th>\n",
       "      <th>topic303</th>\n",
       "      <th>topic304</th>\n",
       "      <th>topic305</th>\n",
       "      <th>topic306</th>\n",
       "      <th>topic307</th>\n",
       "      <th>topic308</th>\n",
       "      <th>topic309</th>\n",
       "      <th>topic310</th>\n",
       "      <th>topic311</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sent0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       topic0  topic1  topic2  topic3  topic4  topic5  topic6  topic7  topic8  \\\n",
       "sent0     0.0     0.0     0.0    0.00     0.0     0.0     0.0     0.0     0.0   \n",
       "sent1     0.0     0.0     0.0    0.45     0.0     0.0     0.0     0.0     0.0   \n",
       "sent2     0.0     0.0     0.0    0.00     0.0     0.0     0.0     0.0     0.0   \n",
       "sent3     0.0     0.0     0.0    0.00     0.0     0.0     0.0     0.0     0.0   \n",
       "sent4     0.0     0.0     0.0    0.00     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "       topic9  ...  topic302  topic303  topic304  topic305  topic306  \\\n",
       "sent0     0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "sent1     0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "sent2     0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "sent3     0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "sent4     0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "       topic307  topic308  topic309  topic310  topic311  \n",
       "sent0       0.0       0.0       0.0       0.0       0.0  \n",
       "sent1       0.0       0.0       0.0       0.0       0.0  \n",
       "sent2       0.0       0.0       0.0       0.0       0.0  \n",
       "sent3       0.0       0.0       0.0       0.0       0.0  \n",
       "sent4       0.0       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 312 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldia312_topic_vectors=ldia312.transform(bow_docs)\n",
    "columns312=['topic{}'.format(i) for i in range(ldia312.n_components)]\n",
    "ldia312_topic_vectors=pd.DataFrame(ldia312_topic_vectors,index=index,columns=columns312)\n",
    "ldia312_topic_vectors.round(2).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use LDiA topic vectors (created from BOW vectors) to train LDA model (simple binary classifier), in the similar way it was done with PCA topic vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.739, 0.624)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(ldia312_topic_vectors,df.score,test_size=0.33,\n",
    "                                               random_state=256242)\n",
    "lda=LDA(n_components=1)\n",
    "lda=lda.fit(X_train,y_train)\n",
    "df['ldia312_sentiment']=lda.predict(ldia312_topic_vectors)\n",
    "# accuracy for train and test sets\n",
    "round(float(lda.score(X_train,y_train)),3),   round(float(lda.score(X_test,y_test)),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f) LDA classification with 256 LDiA topic vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>...</th>\n",
       "      <th>topic246</th>\n",
       "      <th>topic247</th>\n",
       "      <th>topic248</th>\n",
       "      <th>topic249</th>\n",
       "      <th>topic250</th>\n",
       "      <th>topic251</th>\n",
       "      <th>topic252</th>\n",
       "      <th>topic253</th>\n",
       "      <th>topic254</th>\n",
       "      <th>topic255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sent0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       topic0  topic1  topic2  topic3  topic4  topic5  topic6  topic7  topic8  \\\n",
       "sent0     0.0    0.00     0.0     0.0     0.0     0.0     0.0    0.00     0.0   \n",
       "sent1     0.0    0.32     0.0     0.0     0.0     0.0     0.0    0.00     0.0   \n",
       "sent2     0.0    0.00     0.0     0.0     0.0     0.0     0.0    0.00     0.0   \n",
       "sent3     0.0    0.00     0.0     0.0     0.0     0.0     0.0    0.78     0.0   \n",
       "sent4     0.0    0.00     0.0     0.0     0.0     0.0     0.0    0.00     0.0   \n",
       "\n",
       "       topic9  ...  topic246  topic247  topic248  topic249  topic250  \\\n",
       "sent0     0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "sent1     0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "sent2     0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "sent3     0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "sent4     0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "       topic251  topic252  topic253  topic254  topic255  \n",
       "sent0       0.0       0.0       0.0       0.0       0.0  \n",
       "sent1       0.0       0.0       0.0       0.0       0.0  \n",
       "sent2       0.0       0.0       0.0       0.0       0.0  \n",
       "sent3       0.0       0.0       0.0       0.0       0.0  \n",
       "sent4       0.0       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 256 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldia256=LDiA(n_components=256,learning_method='batch')\n",
    "ldia256=ldia256.fit(bow_docs)\n",
    "# Let's compute 256-D topic vectors for all the sentences\n",
    "ldia256_topic_vectors=ldia256.transform(bow_docs)\n",
    "columns256=['topic{}'.format(i) for i in range(ldia256.n_components)]\n",
    "ldia256_topic_vectors=pd.DataFrame(ldia256_topic_vectors,index=index,columns=columns256)\n",
    "ldia256_topic_vectors.round(2).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.75, 0.64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA model (classifier training)\n",
    "X_train,X_test,y_train,y_test=train_test_split(ldia256_topic_vectors,df.score,test_size=0.33,\n",
    "                                               random_state=256242)\n",
    "lda=LDA(n_components=1)\n",
    "lda=lda.fit(X_train,y_train)\n",
    "df['ldia256_sentiment']=lda.predict(ldia256_topic_vectors)\n",
    "# Let's look at accuracy for train and test set\n",
    "round(float(lda.score(X_train,y_train)),3),  round(float(lda.score(X_test,y_test)),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g) LDA classification with 384 LDiA topic vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>...</th>\n",
       "      <th>topic374</th>\n",
       "      <th>topic375</th>\n",
       "      <th>topic376</th>\n",
       "      <th>topic377</th>\n",
       "      <th>topic378</th>\n",
       "      <th>topic379</th>\n",
       "      <th>topic380</th>\n",
       "      <th>topic381</th>\n",
       "      <th>topic382</th>\n",
       "      <th>topic383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sent0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       topic0  topic1  topic2  topic3  topic4  topic5  topic6  topic7  topic8  \\\n",
       "sent0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "sent1     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "sent2     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "sent3     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "sent4     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "       topic9  ...  topic374  topic375  topic376  topic377  topic378  \\\n",
       "sent0     0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "sent1     0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "sent2     0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "sent3     0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "sent4     0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "       topic379  topic380  topic381  topic382  topic383  \n",
       "sent0       0.0       0.0       0.0       0.0       0.0  \n",
       "sent1       0.0       0.0       0.0       0.0       0.0  \n",
       "sent2       0.0       0.0       0.0       0.0       0.0  \n",
       "sent3       0.0       0.0       0.0       0.0       0.0  \n",
       "sent4       0.0       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 384 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldia384=LDiA(n_components=384,learning_method='batch')\n",
    "ldia384=ldia384.fit(bow_docs)\n",
    "# Let's compute 384-D topic vectors for all the sentences\n",
    "ldia384_topic_vectors=ldia384.transform(bow_docs)\n",
    "columns384=['topic{}'.format(i) for i in range(ldia384.n_components)]\n",
    "ldia384_topic_vectors=pd.DataFrame(ldia384_topic_vectors,index=index,columns=columns384)\n",
    "ldia384_topic_vectors.round(2).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.778, 0.625)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(ldia384_topic_vectors,df.score,test_size=0.33,\n",
    "                                               random_state=256242)\n",
    "lda=LDA(n_components=1)\n",
    "lda=lda.fit(X_train,y_train)\n",
    "df['ldia384_sentiment']=lda.predict(ldia384_topic_vectors)\n",
    "# accuracy for train and test sets\n",
    "round(float(lda.score(X_train,y_train)),3),   round(float(lda.score(X_test,y_test)),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### h) LDA classification with 512 LDiA topic vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>...</th>\n",
       "      <th>topic502</th>\n",
       "      <th>topic503</th>\n",
       "      <th>topic504</th>\n",
       "      <th>topic505</th>\n",
       "      <th>topic506</th>\n",
       "      <th>topic507</th>\n",
       "      <th>topic508</th>\n",
       "      <th>topic509</th>\n",
       "      <th>topic510</th>\n",
       "      <th>topic511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sent0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       topic0  topic1  topic2  topic3  topic4  topic5  topic6  topic7  topic8  \\\n",
       "sent0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "sent1     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "sent2     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "sent3     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "sent4     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "       topic9  ...  topic502  topic503  topic504  topic505  topic506  \\\n",
       "sent0     0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "sent1     0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "sent2     0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "sent3     0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "sent4     0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "       topic507  topic508  topic509  topic510  topic511  \n",
       "sent0       0.0       0.0       0.0       0.0       0.0  \n",
       "sent1       0.0       0.0       0.0       0.0       0.0  \n",
       "sent2       0.0       0.0       0.0       0.0       0.0  \n",
       "sent3       0.0       0.0       0.0       0.0       0.0  \n",
       "sent4       0.0       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 512 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldia512=LDiA(n_components=512,learning_method='batch')\n",
    "ldia512=ldia512.fit(bow_docs)\n",
    "# Let's compute 512-D topic vectors for all the sentences\n",
    "ldia512_topic_vectors=ldia512.transform(bow_docs)\n",
    "columns512=['topic{}'.format(i) for i in range(ldia512.n_components)]\n",
    "ldia512_topic_vectors=pd.DataFrame(ldia512_topic_vectors,index=index,columns=columns512)\n",
    "ldia512_topic_vectors.round(2).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.805, 0.665)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(ldia512_topic_vectors,df.score,test_size=0.33,\n",
    "                                               random_state=256242)\n",
    "lda=LDA(n_components=1)\n",
    "lda=lda.fit(X_train,y_train)\n",
    "df['ldia512_sentiment']=lda.predict(ldia512_topic_vectors)\n",
    "# accuracy for train and test sets\n",
    "round(float(lda.score(X_train,y_train)),3),   round(float(lda.score(X_test,y_test)),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) LDA classification with 1024 LDiA topic vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>...</th>\n",
       "      <th>topic1014</th>\n",
       "      <th>topic1015</th>\n",
       "      <th>topic1016</th>\n",
       "      <th>topic1017</th>\n",
       "      <th>topic1018</th>\n",
       "      <th>topic1019</th>\n",
       "      <th>topic1020</th>\n",
       "      <th>topic1021</th>\n",
       "      <th>topic1022</th>\n",
       "      <th>topic1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sent0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       topic0  topic1  topic2  topic3  topic4  topic5  topic6  topic7  topic8  \\\n",
       "sent0     0.0     0.0     0.0     0.0    0.71     0.0     0.0     0.0     0.0   \n",
       "sent1     0.0     0.0     0.0     0.0    0.00     0.0     0.0     0.0     0.0   \n",
       "sent2     0.0     0.0     0.0     0.0    0.00     0.0     0.0     0.0     0.0   \n",
       "sent3     0.0     0.0     0.0     0.0    0.00     0.0     0.0     0.0     0.0   \n",
       "sent4     0.0     0.0     0.0     0.0    0.00     0.0     0.0     0.0     0.0   \n",
       "\n",
       "       topic9  ...  topic1014  topic1015  topic1016  topic1017  topic1018  \\\n",
       "sent0     0.0  ...        0.0        0.0        0.0        0.0        0.0   \n",
       "sent1     0.0  ...        0.0        0.0        0.0        0.0        0.0   \n",
       "sent2     0.0  ...        0.0        0.0        0.0        0.0        0.0   \n",
       "sent3     0.0  ...        0.0        0.0        0.0        0.0        0.0   \n",
       "sent4     0.0  ...        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "       topic1019  topic1020  topic1021  topic1022  topic1023  \n",
       "sent0        0.0        0.0        0.0        0.0        0.0  \n",
       "sent1        0.0        0.0        0.0        0.0        0.0  \n",
       "sent2        0.0        0.0        0.0        0.0        0.0  \n",
       "sent3        0.0        0.0        0.0        0.0        0.0  \n",
       "sent4        0.0        0.0        0.0        0.0        0.0  \n",
       "\n",
       "[5 rows x 1024 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldia1024=LDiA(n_components=1024,learning_method='batch')\n",
    "ldia1024=ldia1024.fit(bow_docs)\n",
    "# Let's compute 1024-D topic vectors for all the sentences\n",
    "ldia1024_topic_vectors=ldia1024.transform(bow_docs)\n",
    "columns1024=['topic{}'.format(i) for i in range(ldia1024.n_components)]\n",
    "ldia1024_topic_vectors=pd.DataFrame(ldia1024_topic_vectors,index=index,columns=columns1024)\n",
    "ldia1024_topic_vectors.round(2).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.839, 0.724)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(ldia1024_topic_vectors,df.score,test_size=0.33,\n",
    "                                               random_state=256242)\n",
    "lda=LDA(n_components=1)\n",
    "lda=lda.fit(X_train,y_train)\n",
    "df['ldia1024_sentiment']=lda.predict(ldia1024_topic_vectors)\n",
    "# accuracy for train and test sets\n",
    "round(float(lda.score(X_train,y_train)),3),   round(float(lda.score(X_test,y_test)),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### j) LDA classification with 2048 LDiA topic vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>...</th>\n",
       "      <th>topic2038</th>\n",
       "      <th>topic2039</th>\n",
       "      <th>topic2040</th>\n",
       "      <th>topic2041</th>\n",
       "      <th>topic2042</th>\n",
       "      <th>topic2043</th>\n",
       "      <th>topic2044</th>\n",
       "      <th>topic2045</th>\n",
       "      <th>topic2046</th>\n",
       "      <th>topic2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sent0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2048 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       topic0  topic1  topic2  topic3  topic4  topic5  topic6  topic7  topic8  \\\n",
       "sent0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "sent1     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "sent2     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "sent3     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "sent4     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "       topic9  ...  topic2038  topic2039  topic2040  topic2041  topic2042  \\\n",
       "sent0     0.0  ...        0.0        0.0        0.0       0.07        0.0   \n",
       "sent1     0.0  ...        0.0        0.0        0.0       0.00        0.0   \n",
       "sent2     0.0  ...        0.0        0.0        0.0       0.00        0.0   \n",
       "sent3     0.0  ...        0.0        0.0        0.0       0.00        0.0   \n",
       "sent4     0.0  ...        0.0        0.0        0.0       0.00        0.0   \n",
       "\n",
       "       topic2043  topic2044  topic2045  topic2046  topic2047  \n",
       "sent0        0.0        0.0        0.0        0.0        0.0  \n",
       "sent1        0.0        0.0        0.0        0.0        0.0  \n",
       "sent2        0.0        0.0        0.0        0.0        0.0  \n",
       "sent3        0.0        0.0        0.0        0.0        0.0  \n",
       "sent4        0.0        0.0        0.0        0.0        0.0  \n",
       "\n",
       "[5 rows x 2048 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldia2048=LDiA(n_components=2048,learning_method='batch')\n",
    "ldia2048=ldia2048.fit(bow_docs)\n",
    "# Let's compute 2048-D topic vectors for all the sentences\n",
    "ldia2048_topic_vectors=ldia2048.transform(bow_docs)\n",
    "columns2048=['topic{}'.format(i) for i in range(ldia2048.n_components)]\n",
    "ldia2048_topic_vectors=pd.DataFrame(ldia2048_topic_vectors,index=index,columns=columns2048)\n",
    "ldia2048_topic_vectors.round(2).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.68, 0.649)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(ldia2048_topic_vectors,df.score,test_size=0.33,\n",
    "                                               random_state=256242)\n",
    "lda=LDA(n_components=1)\n",
    "lda=lda.fit(X_train,y_train)\n",
    "df['ldia2048_sentiment']=lda.predict(ldia2048_topic_vectors)\n",
    "# accuracy for train and test sets\n",
    "round(float(lda.score(X_train,y_train)),3),   round(float(lda.score(X_test,y_test)),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook the spam classification was performed with ten methods:\n",
    "- a) LDA classification done with Tf-idf vectors: test accuracy 0.682\n",
    "- b) LDA classification with 256 topic vectors created by LSA (PCA):test accuracy 0.776\n",
    "- c) LDA classification with 384 topic vectors created by LSA (PCA):test accuracy 0.8   <- Best result with LSA (PCA)\n",
    "- d) LDA classification with 312 topic vectors created by LSA (PCA):test accuracy 0.789\n",
    "- e) LDA classification with 312 topic vectors created by LDiA:test accuracy 0.624\n",
    "- f) LDA classification with 256 topic vectors created by LDiA:test accuracy 0.64\n",
    "- g) LDA classification with 384 topic vectors created by LDiA:test accuracy 0.625\n",
    "- h) LDA classification with 512 topic vectors created by LDiA:test accuracy 0.665\n",
    "- i) LDA classification with 1024 topic vectors created by LDiA:test accuracy 0.724  <- Best result with LDiA\n",
    "- j) LDA classification with 2048 topic vectors created by LDiA:test accuracy 0.649\n",
    "\n",
    "The results show that some kind of dimension reduction method is needed, since a) did not provide very good results. The best accuracy score was obtained with c) , when LSA, Latent semantic analysis with PCA was used for creating 384 topic vectors. LDA classification was then performed with these 384 topic vectors.\n",
    "\n",
    "If instead of PCA, LDiA, Latent Dirichlet Allocation, was used for creating the topic vectors, a larger number of dimensions in terms of topic vectors were required. The best result with LDiA was obtained with 1024 topic vectors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
