{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "conda-env-python-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "NLP_3_wordvectors.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHTgwq4BdBpK",
        "colab_type": "text"
      },
      "source": [
        "# Word vectors for reasoning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3siADC9hdBpg",
        "colab_type": "text"
      },
      "source": [
        "In this notebook I experiment with word vectors. Two alternative methods are tested:\n",
        "- Word2vec from Google\n",
        "- FastText from Facebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un4bdO-NdBp1",
        "colab_type": "code",
        "outputId": "64828e0c-33b2-45a5-c155-d0de71c5f8db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Load libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.options.display.width=120\n",
        "#pd.set_option('display.width',75)\n",
        "#pd.options.display.max_columns=8\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "#import nlpia\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "from nltk.tokenize.casual import casual_tokenize\n",
        "from collections import Counter\n",
        "from collections import OrderedDict\n",
        "import copy\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxsGA0G1dBqr",
        "colab_type": "text"
      },
      "source": [
        "## 1A) Loading gensim.word2vec module (from Google)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsrKlhgodBq3",
        "colab_type": "text"
      },
      "source": [
        "You can also do it so that find the original model (binary format) with google search: \"Word2vec models pretrained on Google News documents\"\n",
        "- put it in the local path, and then you can load with below script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51bbI2D0dBrF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim.downloader as api"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxYfuVZfdBr3",
        "colab_type": "code",
        "outputId": "dff73d13-44b4-4061-f5f8-ff0ac81d30e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "wv=api.load('word2vec-google-news-300')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_pTZXEfhW_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egDEJpMSdBsb",
        "colab_type": "text"
      },
      "source": [
        "### a) Experimenting with word2vec values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Np75mZDdBsn",
        "colab_type": "text"
      },
      "source": [
        "Note, you need to insert wv in front of it (the earlier method without it is deprecated).\n",
        "\n",
        "most_similar() method:\n",
        "- most_similar() method can be used for finding nearest neighbors for any given word vector.\n",
        "- argument: positive adds the vectors together\n",
        "- argument: negative subtracts the vectors (excludes them)\n",
        "- argument: topn returns top n values \n",
        "\n",
        "doesnt_match() method:\n",
        "- determines the most unrelated term (with highest distance to all other terms in the input list).\n",
        "\n",
        "similarity() method:\n",
        "- calculates cosine similarity between two words\n",
        "\n",
        "get the word vector for a word (300 dimensions of floats)\n",
        "- word_vectors['word']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deOPD9psdBsx",
        "colab_type": "code",
        "outputId": "2e28e779-41f8-4db6-b503-45bf14c6ec57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "wv.most_similar('cooking')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('cook', 0.7584654092788696),\n",
              " ('Cooking', 0.7552591562271118),\n",
              " ('baking', 0.6751805543899536),\n",
              " ('cookery', 0.6722506284713745),\n",
              " ('humongous_belly', 0.6695600748062134),\n",
              " ('cooks', 0.6584445834159851),\n",
              " ('sauteeing', 0.6277279853820801),\n",
              " ('COOKING_DEADLINE_LOGO_Logo', 0.6251790523529053),\n",
              " ('About_Dishing', 0.6237301826477051),\n",
              " ('caramelizing_onions', 0.6213988065719604)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8PrfTWXdBtZ",
        "colab_type": "code",
        "outputId": "afa7fabc-530f-46b1-c227-853171220345",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "wv.most_similar(positive=['cooking','potatoes'],topn=5)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('cook', 0.6973531246185303),\n",
              " ('oven_roasting', 0.6754531860351562),\n",
              " ('Slow_cooker', 0.6742031574249268),\n",
              " ('sweet_potatoes', 0.6600280404090881),\n",
              " ('stir_fry_vegetables', 0.6548759341239929)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eulXx6wUdBt0",
        "colab_type": "code",
        "outputId": "4a0281a8-d113-489e-808a-75d4f6230872",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "wv.doesnt_match(\"potatoes milk cake computer\".split())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'computer'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2ofL_xSdBuQ",
        "colab_type": "code",
        "outputId": "aa598512-d351-4247-a4ff-77eea81df961",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Perform calculations (e.g. king+woman-man=queen)\n",
        "wv.most_similar(positive=['king','woman'],negative=['man'],topn=2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.7118192911148071), ('monarch', 0.6189674139022827)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPOlc8PEdBur",
        "colab_type": "code",
        "outputId": "bb25555b-2a62-46e2-f44c-a02fab5e5820",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "wv.similarity('princess','queen')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7070532"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVZMagondBvJ",
        "colab_type": "text"
      },
      "source": [
        "## 1B) Generating you own word vector representations (with Word2Vec from Google)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67cjOAztdBvV",
        "colab_type": "text"
      },
      "source": [
        "This may be needed if you use a specific domain (e.g. technical vocabulary), not present in Google News."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpVukWR0dBvd",
        "colab_type": "text"
      },
      "source": [
        "### a) Preprocess your documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7NC6I9WdBvk",
        "colab_type": "text"
      },
      "source": [
        "gensimword2vec model expects a list of sentences where each sentence is broken up into tokens.\n",
        "- Detector Morse is a sentence segmenter that improves upon the accuracy segmenter available in NLTK. (https://github.com/cslu-nlp/DetectorMorse)\n",
        "- Here we use nltk's sent_tokenize() method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9Unit3pdBvu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc=\"\"\"To provide early intervention/early childhood special education services to eligible chidren and their families. Essential job functions. \\\n",
        "Participate as a transdisciplinary team member to complete educational assessments for.\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L88YkJixdBwC",
        "colab_type": "code",
        "outputId": "66f11f28-7bf6-4574-fec9-f803ec3d0f9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# note: sent_tokenize requires nltk.download('punkt') in the import section.\n",
        "sentences = nltk.tokenize.sent_tokenize(doc)\n",
        "sentences"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['To provide early intervention/early childhood special education services to eligible chidren and their families.',\n",
              " 'Essential job functions.',\n",
              " 'Participate as a transdisciplinary team member to complete educational assessments for.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHGVDlcYdBwa",
        "colab_type": "code",
        "outputId": "c4025417-c496-4543-d21e-cf32a05ec7dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        }
      },
      "source": [
        "tokenizer=TreebankWordTokenizer()\n",
        "token_list=[]\n",
        "#punctuation=['.','!','?']\n",
        "for sentence in sentences:\n",
        "    tokens=tokenizer.tokenize(sentence.lower())\n",
        "    token_list.append(tokens)\n",
        "token_list"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['to',\n",
              "  'provide',\n",
              "  'early',\n",
              "  'intervention/early',\n",
              "  'childhood',\n",
              "  'special',\n",
              "  'education',\n",
              "  'services',\n",
              "  'to',\n",
              "  'eligible',\n",
              "  'chidren',\n",
              "  'and',\n",
              "  'their',\n",
              "  'families',\n",
              "  '.'],\n",
              " ['essential', 'job', 'functions', '.'],\n",
              " ['participate',\n",
              "  'as',\n",
              "  'a',\n",
              "  'transdisciplinary',\n",
              "  'team',\n",
              "  'member',\n",
              "  'to',\n",
              "  'complete',\n",
              "  'educational',\n",
              "  'assessments',\n",
              "  'for',\n",
              "  '.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXnIUptwdBw7",
        "colab_type": "text"
      },
      "source": [
        "### b) Train your domain-specific Word2Vec model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oEDkDnzdBxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models.word2vec import Word2Vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujGeOcN6dBxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_features=300 # number of vector elements (dimensions) to represent the word vector. 300 is used in Google News model.\n",
        "min_word_count=1 # min number of word count to be considered. If the corpus is small, decrease this value (could be e.g. 3 for larger corpus)\n",
        "num_workers=2 # number of CPU cores\n",
        "window_size=6 # window for skipgram or continuous bag-of-words approach\n",
        "subsampling=1e-3 # supsampling rate for frequent words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvzmUGSRdBxy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Perform training for your domain-specific Word2Vec model\n",
        "model=Word2Vec(token_list,workers=num_workers,size=num_features,min_count=min_word_count,window=window_size,sample=subsampling)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-HeGclsdByF",
        "colab_type": "text"
      },
      "source": [
        "Word2Vec models can consumer quite a lot of memory. But it is only the weight matrix that is of interest.\n",
        "- You can reduce the memory footprint by freezing the model and discarding the unnecessary information\n",
        "- Following command will discard the unneeded output weights of your neural network: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mgm4Yn0dByL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove unneeded output weights, only hidden weights are needed.\n",
        "model.init_sims(replace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULSYyUJddByg",
        "colab_type": "text"
      },
      "source": [
        "### c) Save the model - load it back"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXIse_rFdByn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the trained model for later use.\n",
        "model_name=\"my_domain_specific_word2vec_model\"\n",
        "model.save(model_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdNwVncjdBy5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the model\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "model_name=\"my_domain_specific_word2vec_model\"\n",
        "model=Word2Vec.load(model_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G--Hz0zHdBzP",
        "colab_type": "text"
      },
      "source": [
        "### d) Test the trained Word2Vec model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvIXTU2TdBzU",
        "colab_type": "code",
        "outputId": "e6f86129-cc80-48ac-c01b-147833706b04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# Experiment with your new model\n",
        "model.most_similar('childhood',topn=3)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('to', 0.10461775958538055),\n",
              " ('education', 0.10317566990852356),\n",
              " ('educational', 0.07376974076032639)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZRcIxIEdBz9",
        "colab_type": "code",
        "outputId": "bb74a006-1bd7-40ec-8b8a-72bc4f89d9b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "model.wv.most_similar(positive=['childhood','education'],topn=3)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('participate', 0.10716139525175095),\n",
              " ('educational', 0.10102303326129913),\n",
              " ('intervention/early', 0.08609788119792938)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2sMmE26dB0O",
        "colab_type": "code",
        "outputId": "db64ab56-bf54-49ab-cf1a-4e04bcd37840",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Which word in the list doesn't belong there\n",
        "model.wv.doesnt_match(\"participate childhood education complete\".split())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'complete'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQHHWqPidB0h",
        "colab_type": "code",
        "outputId": "213d2db2-5ad5-4112-b019-3690c7d79d78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model.wv.similarity('participate','participate')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaclYQCHdB00",
        "colab_type": "code",
        "outputId": "277f791d-eea7-4ad6-b039-b3aa3d392bfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model.wv.similarity('participate','complete')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.040114988"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSRV2fMVdB1G",
        "colab_type": "code",
        "outputId": "7df293eb-718a-4346-ad56-439a4d1d20a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Look at the vector values\n",
        "model.wv['participate']"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2.45387983e-02, -2.14709640e-02, -5.51058054e-02, -2.36385334e-02,\n",
              "        8.53215158e-02, -6.39206124e-03, -1.00440048e-01,  5.49790077e-02,\n",
              "        8.93002301e-02,  8.78949761e-02,  8.77754390e-02, -7.74674416e-02,\n",
              "        1.98067855e-02, -6.23886893e-03, -2.56746337e-02,  6.62396848e-02,\n",
              "        8.54819641e-02, -7.59971812e-02, -5.17119132e-02,  6.56401813e-02,\n",
              "       -3.15501355e-02, -9.94994566e-02,  4.85849828e-02, -5.00031561e-02,\n",
              "       -9.37737375e-02, -4.30966467e-02, -5.49378991e-02, -9.36845839e-02,\n",
              "       -8.78868178e-02, -6.88809305e-02, -5.06178774e-02,  7.10132122e-02,\n",
              "       -6.62240535e-02, -2.52168216e-02, -4.92332457e-03, -6.67347759e-02,\n",
              "        6.06727302e-02,  9.75582749e-03,  2.43449733e-02,  5.60075603e-02,\n",
              "       -1.53844031e-02, -1.02046043e-01, -6.71053603e-02, -8.19390938e-02,\n",
              "        1.07317166e-02, -7.80324489e-02, -3.14557999e-02, -7.44090900e-02,\n",
              "       -1.39754508e-02, -3.46920307e-04,  3.73141393e-02, -7.92203620e-02,\n",
              "       -1.80251114e-02, -8.97566527e-02,  6.61786199e-02, -1.29757430e-02,\n",
              "       -2.66460553e-02,  6.45300150e-02,  5.33415191e-02,  3.73051055e-02,\n",
              "       -4.31916043e-02, -2.53306031e-02, -2.80296542e-02, -5.49057797e-02,\n",
              "       -5.30312881e-02,  8.43338221e-02, -3.25577408e-02,  6.37174547e-02,\n",
              "        4.05574292e-02, -6.15456775e-02, -3.74173708e-02, -2.88503934e-02,\n",
              "       -6.64286539e-02, -8.28195289e-02,  7.73785729e-03, -5.50385751e-02,\n",
              "       -3.82753313e-02, -2.93877777e-02,  3.46320644e-02,  8.86082128e-02,\n",
              "       -6.28719106e-02, -3.23103257e-02,  1.80498511e-02, -1.81597844e-02,\n",
              "       -6.75458014e-02, -8.91896337e-02, -5.09620011e-02,  1.92192588e-02,\n",
              "        9.20215920e-02,  9.45889279e-02, -6.97552860e-02, -3.00286189e-02,\n",
              "       -6.47574440e-02,  4.50325161e-02,  7.36145675e-02, -2.59693787e-02,\n",
              "        9.51577723e-02, -1.04816584e-02, -7.83774331e-02,  3.07029076e-02,\n",
              "        3.71624567e-02, -1.72587447e-02, -3.00297048e-02, -9.84221920e-02,\n",
              "        4.46385257e-02, -5.54959588e-02, -2.36236304e-02,  7.21276626e-02,\n",
              "       -5.15774824e-02, -1.52110271e-02, -9.39175487e-02,  5.58115244e-02,\n",
              "       -1.20472256e-02, -9.31170769e-03, -3.79532687e-02, -1.01089984e-01,\n",
              "       -7.68673494e-02,  3.47545706e-02,  8.98677632e-02,  3.43542993e-02,\n",
              "        3.69361192e-02, -1.01038357e-02,  3.74214202e-02, -8.38421881e-02,\n",
              "       -1.09734759e-03, -1.57933906e-02, -8.80803615e-02, -4.67586070e-02,\n",
              "        8.98308977e-02,  5.23202792e-02, -8.82059038e-02, -9.99684408e-02,\n",
              "        6.47411542e-03,  7.67665952e-02, -7.94426650e-02, -8.75597298e-02,\n",
              "        1.38336318e-02, -6.63088113e-02, -2.88923457e-02, -8.05078149e-02,\n",
              "        7.51589984e-02,  5.43074012e-02, -7.71903396e-02, -3.88504006e-02,\n",
              "        2.87988372e-02,  4.88710292e-02,  1.32520441e-02, -8.48866478e-02,\n",
              "       -8.92222524e-05, -7.68246874e-02,  7.21099749e-02, -6.92205355e-02,\n",
              "        7.70113990e-03, -4.78690267e-02,  9.43308920e-02, -2.49785855e-02,\n",
              "        5.82149141e-02, -4.88682128e-02, -6.09244481e-02, -1.12060932e-02,\n",
              "       -7.46833766e-03, -1.17778720e-03,  5.09534702e-02,  6.55173436e-02,\n",
              "       -5.28752282e-02,  9.71866697e-02,  8.83087814e-02, -8.44326690e-02,\n",
              "        3.37727405e-02,  3.68185202e-03, -6.05097786e-03,  3.08747236e-02,\n",
              "       -6.24813884e-02, -8.67983401e-02, -4.23196815e-02,  9.94138420e-02,\n",
              "       -5.72708361e-02,  7.05010891e-02, -2.80286651e-02,  2.39234529e-02,\n",
              "        1.54441474e-02,  5.79833426e-02, -2.74376050e-02,  5.12375161e-02,\n",
              "       -1.31970877e-02,  9.33051202e-03,  6.23242036e-02, -7.67629519e-02,\n",
              "       -8.07726383e-02,  1.37503911e-02, -4.48167212e-02,  8.47510174e-02,\n",
              "        3.48326601e-02,  3.01498175e-02,  6.04189821e-02, -8.21082145e-02,\n",
              "        2.71597598e-02, -4.30078320e-02, -2.34213006e-02,  8.93066078e-02,\n",
              "        7.01990649e-02, -8.29554424e-02, -4.50436287e-02,  8.38346630e-02,\n",
              "        1.14005031e-02,  1.42270271e-02,  9.75954980e-02,  3.85260321e-02,\n",
              "       -8.70263651e-02,  8.01195726e-02,  6.84395954e-02, -1.01039745e-01,\n",
              "       -8.52465779e-02,  6.28338084e-02, -9.68196094e-02,  8.07818174e-02,\n",
              "       -4.75643165e-02,  3.67220640e-02, -5.67502230e-02,  4.35807966e-02,\n",
              "        2.63189301e-02,  6.30842224e-02, -3.96626033e-02,  2.15418660e-03,\n",
              "       -5.67519777e-02, -4.02819179e-03, -5.65869547e-02, -9.39846132e-03,\n",
              "        5.41732162e-02,  4.48476449e-02,  4.26910296e-02,  7.89858226e-04,\n",
              "        9.70369056e-02,  3.25650945e-02,  6.38015196e-02,  2.56439019e-02,\n",
              "       -5.99808730e-02,  7.66048674e-03, -2.95871850e-02,  6.88290596e-02,\n",
              "        4.04674597e-02,  3.65810730e-02, -1.07797002e-03,  4.05307636e-02,\n",
              "        9.37998071e-02,  1.94904730e-02, -6.75650388e-02, -7.72377551e-02,\n",
              "       -2.59403568e-02,  3.97703759e-02, -2.86521707e-02,  4.53747734e-02,\n",
              "       -3.32856700e-02, -3.66256163e-02,  9.12621059e-03, -5.72211742e-02,\n",
              "       -1.36303091e-02,  1.10765509e-02,  2.21672580e-02, -3.96912396e-02,\n",
              "       -5.55651188e-02, -7.00901225e-02, -3.17081660e-02,  2.63104104e-02,\n",
              "        2.14067679e-02, -8.71643350e-02,  4.95385155e-02,  8.30409527e-02,\n",
              "        7.55022317e-02,  1.65974684e-02, -4.21821326e-02, -5.37837371e-02,\n",
              "        7.95445442e-02,  8.27828646e-02,  3.66463438e-02,  7.97404721e-02,\n",
              "        1.25458287e-02, -7.10119680e-02,  4.11638282e-02, -7.82964006e-02,\n",
              "        4.45560664e-02,  3.38740051e-02, -7.21789673e-02, -3.84102128e-02,\n",
              "       -4.13738266e-02, -6.07181825e-02, -3.23789567e-02, -2.38457005e-02,\n",
              "       -4.62890714e-02, -2.79122069e-02, -3.07089929e-02,  5.83220795e-02,\n",
              "       -5.04544117e-02, -7.74744898e-02, -4.27195393e-02,  9.22251418e-02,\n",
              "        8.81687999e-02, -6.49443716e-02, -9.92388502e-02,  3.46574001e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcIDxL44dB1c",
        "colab_type": "text"
      },
      "source": [
        "### e) Comparison of Word2Vec vs. LSA topic vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4E1Q7FICdB1i",
        "colab_type": "text"
      },
      "source": [
        "Topic-document vectors: \n",
        "- with LSA : sum of the topic-word vectors for all the words in the documents\n",
        "- with Word2Vec: sum of all Word2Vec word vectors in each document. Quite close how Doc2vec document vectors work (discussed later)\n",
        "\n",
        "Word2Vec gets more use out of the same number of words in documents since it uses sliding window\n",
        "- thus it reuses the same words five times before sliding on.\n",
        "    \n",
        "Comparison:\n",
        "- LSA topic vectors: faster training, better discrimination between longer documents\n",
        "- Word2Vec and Glove: more efficient use of large corpora, more accurate reasoning with words (analogy questions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12dc7V48dB1n",
        "colab_type": "text"
      },
      "source": [
        "### f) Visualizing word relationships"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZFfN6BldB1r",
        "colab_type": "text"
      },
      "source": [
        "Note: quick visualization of your word model can be done with TensorBoard's word embedding visualization functionality (see chapter 13)\n",
        "\n",
        "Let's visualize the word vectors here in 2D to look if we can find some discoveries.\n",
        "- First load all word vectors from Google Word2Vec model of Google News corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l7RDq_2dB1v",
        "colab_type": "code",
        "outputId": "de9b23fb-83ef-4eff-d744-e4e3820216f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# It was loaded already in this notebook. Let's check its length\n",
        "len(wv.vocab)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6HP8Gx_dB2B",
        "colab_type": "code",
        "outputId": "df0fcff6-b243-43ef-b0d4-6a36ccf74125",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "# See pages 208-213 from the book for 2D visualisation, using PCA.\n",
        "import pandas as pd\n",
        "vocab=pd.Series(wv.vocab)\n",
        "vocab.iloc[100000:100006]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "distinctiveness    Vocab(count:2900000, index:100000)\n",
              "Namco_Bandai       Vocab(count:2899999, index:100001)\n",
              "ramparts           Vocab(count:2899998, index:100002)\n",
              "Linden_Lab         Vocab(count:2899997, index:100003)\n",
              "Revolutions        Vocab(count:2899996, index:100004)\n",
              "Henderson_Nev.     Vocab(count:2899995, index:100005)\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMmXq6Fikjoq",
        "colab_type": "code",
        "outputId": "498b0d34-f3c2-424c-f8eb-a1630cc7c7dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "wv['distinctiveness'][0:100]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.14453125,  0.04223633,  0.12304688,  0.07421875, -0.13671875,\n",
              "        0.17871094,  0.06933594, -0.14257812,  0.2265625 ,  0.1640625 ,\n",
              "       -0.3125    ,  0.10986328, -0.09960938,  0.38671875, -0.30078125,\n",
              "       -0.13183594, -0.24316406,  0.30859375, -0.12792969, -0.16015625,\n",
              "       -0.39453125, -0.1484375 , -0.08691406,  0.26367188, -0.13085938,\n",
              "       -0.27539062,  0.11328125, -0.15234375,  0.35742188,  0.07617188,\n",
              "        0.04711914, -0.15332031,  0.07128906,  0.24121094,  0.16601562,\n",
              "       -0.04858398,  0.17578125, -0.19824219, -0.13574219, -0.16699219,\n",
              "       -0.17578125, -0.14257812, -0.09033203,  0.33007812, -0.07373047,\n",
              "       -0.13867188, -0.05541992,  0.37695312,  0.08398438,  0.0859375 ,\n",
              "       -0.14648438,  0.31445312,  0.02905273, -0.14746094,  0.05493164,\n",
              "        0.18652344, -0.26367188, -0.19433594,  0.06787109, -0.05932617,\n",
              "        0.30273438,  0.05737305,  0.14453125, -0.625     , -0.42578125,\n",
              "        0.01165771, -0.10449219, -0.0625    ,  0.14160156, -0.06933594,\n",
              "       -0.06396484, -0.04736328, -0.08789062, -0.48828125, -0.33203125,\n",
              "       -0.02868652,  0.14257812,  0.03808594,  0.375     ,  0.20800781,\n",
              "       -0.16894531, -0.16113281, -0.16210938, -0.00970459, -0.22949219,\n",
              "        0.03857422,  0.05908203,  0.49023438, -0.02807617,  0.15917969,\n",
              "       -0.16113281, -0.35351562, -0.390625  , -0.08642578,  0.07324219,\n",
              "       -0.07910156, -0.3203125 ,  0.05273438, -0.12890625, -0.0534668 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB27GnYJk2PV",
        "colab_type": "code",
        "outputId": "55785b02-ed9b-4e3f-8257-e26ba1da69be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Distance between distinctiveness and distintive\n",
        "import numpy as np\n",
        "np.linalg.norm(wv['distinctiveness']-wv['distinctive']) # Euclidean distance"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.1394858"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGPjEWBek2Jq",
        "colab_type": "code",
        "outputId": "fab1fbc5-f2f3-48c8-eb04-fb953b9f0456",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Cosine similarity is the normalized dot product\n",
        "cos_similarity=np.dot(wv['distinctiveness'],wv['distinctive'])/(\n",
        "    np.linalg.norm(wv['distinctiveness'])*np.linalg.norm(wv['distinctive']))\n",
        "cos_similarity"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5303259"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fob99GZmk2CE",
        "colab_type": "code",
        "outputId": "ace2dffe-7ca1-4ba4-a333-a086b3c404fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Cosine distance\n",
        "1 - cos_similarity"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.46967411041259766"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdWlqhXodB2P",
        "colab_type": "text"
      },
      "source": [
        "### g) Document similarity with Doc2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnMwoZ5MdB2d",
        "colab_type": "text"
      },
      "source": [
        "If you are running on low RAM and you know the number of documents ahead of time you can use preallocated numpy array instead of Python list for training_corpus.\n",
        "- training_corpus=np.empty(len(corpus),dtype(object))\n",
        "- ... training_corpus[i]=..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-fGvS0CdB2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use gensim package to train document vector\n",
        "import multiprocessing\n",
        "num_cores=multiprocessing.cpu_count()  # calculates how many CPU cores are available\n",
        "from gensim.models.doc2vec import TaggedDocument, Doc2Vec   # Doc2Vec contains both word embeddings as well as doc vectors for each doc in your corpus.\n",
        "from gensim.utils import simple_preprocess # crude tokenizer that ignores one-letter words and punctuation. Also other tokenizers work fine.\n",
        "training_corpus=[]\n",
        "for i,text in enumerate(sentences):   # here the corpus is doc variable, where each sentence is considered one doc\n",
        "    tagged_doc=TaggedDocument(simple_preprocess(text),[i])  # documents are annotated with strings or integer tags or whatever info you want to tag your docs\n",
        "    training_corpus.append(tagged_doc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRUkAQSYdB2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=Doc2Vec(size=100,min_count=1,workers=num_cores,iter=10)  # window size of 10 words, dimensions: 100\n",
        "model.build_vocab(training_corpus)\n",
        "model.train(training_corpus,total_examples=model.corpus_count,epochs=model.epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfV9MmD9dB3B",
        "colab_type": "code",
        "outputId": "2adf6192-9d3c-4619-ba96-c25353fe7fa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        }
      },
      "source": [
        "# Then infer documents with the doc2vectors\n",
        "# steps: update the trained vector through 10 steps (iterations) -> quickly train the entire corpus of docs and find similar docs.\n",
        "model.infer_vector(simple_preprocess('This is a completely unseen document'),steps=10)  "
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 5.1482586e-04, -8.7723223e-04, -1.0287223e-03, -1.6943730e-03,\n",
              "       -1.0099850e-03, -1.8903159e-03,  4.4856564e-04, -4.7034067e-03,\n",
              "       -1.1170713e-03, -2.5134217e-03,  2.0423906e-03, -2.5497428e-03,\n",
              "        2.8503904e-04,  4.7316640e-03, -3.8181783e-03, -1.6194887e-03,\n",
              "       -4.3283659e-03,  2.0670765e-03,  4.0842486e-03,  1.3520226e-03,\n",
              "       -1.8441958e-03,  3.7693719e-03, -3.8640937e-03,  2.0029738e-03,\n",
              "        8.4973167e-04,  6.4203358e-04, -6.7998620e-04, -4.0455558e-03,\n",
              "        2.9018931e-03,  3.3808856e-03,  1.2826681e-03,  3.9480086e-03,\n",
              "        2.0543612e-03,  1.7407783e-03,  3.5341850e-03,  4.2284536e-03,\n",
              "       -2.3516305e-03,  4.7414396e-03,  4.2300774e-03,  3.2893044e-03,\n",
              "        3.9262362e-03, -1.0382166e-03,  3.3581874e-03,  1.9825818e-03,\n",
              "        3.6963215e-03, -1.8682105e-04, -1.3601539e-03,  2.2856826e-03,\n",
              "        1.1717859e-03, -4.4503110e-03, -7.2348089e-04, -1.6727307e-03,\n",
              "       -3.4445480e-03, -1.0842012e-03, -4.5640469e-03, -3.4773993e-04,\n",
              "        2.6776621e-03, -2.1958945e-03,  3.4170875e-03,  2.3838135e-03,\n",
              "        1.2025407e-03, -3.7880563e-03,  4.2093224e-03,  2.6954238e-03,\n",
              "       -1.7590645e-03,  7.6729554e-04,  2.9621087e-03,  3.0775717e-03,\n",
              "       -2.4137493e-04, -2.7299358e-03, -1.6867480e-03, -1.6459671e-03,\n",
              "        4.7571589e-03,  3.0066948e-03, -1.5997584e-03, -4.7637410e-03,\n",
              "       -2.4220189e-03,  2.9983902e-03, -2.6387575e-03, -2.7588365e-05,\n",
              "        1.1716947e-03, -4.7392193e-03, -4.4962894e-03, -3.8378451e-03,\n",
              "       -4.8229336e-03, -3.4789727e-03, -1.1897711e-03,  5.5881205e-04,\n",
              "        3.3089959e-03,  2.4813728e-03, -4.1561546e-03, -3.0061312e-03,\n",
              "       -3.3662999e-03,  4.2854236e-03,  1.1757938e-03, -1.4617094e-03,\n",
              "       -4.2046560e-03,  4.9969619e-03,  1.4969960e-03,  6.4054638e-04],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrMMEzS2dB3O",
        "colab_type": "text"
      },
      "source": [
        "Common tasks with Doc2Vec\n",
        "- find similar docs (by calculating cosine distance between each document vector)\n",
        "- cluster the document vectors with something like k-means to create a document classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFfirVt2dB3U",
        "colab_type": "code",
        "outputId": "1797c1a8-4f7c-4b13-ff4a-d92026b943d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        }
      },
      "source": [
        "# Look at document vector\n",
        "model[1]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2.99791526e-03, -1.51098924e-04, -3.53953009e-03,  2.31808261e-03,\n",
              "       -2.16730661e-03, -1.08175015e-03,  8.61137931e-04,  2.15832074e-03,\n",
              "       -4.17979294e-03,  4.41799127e-03, -4.75926092e-03, -3.18557001e-03,\n",
              "       -1.61611976e-03, -6.72612689e-04,  2.24564318e-03,  2.33253697e-03,\n",
              "        1.75195048e-03, -1.52676913e-03, -3.85199487e-03,  8.75639438e-04,\n",
              "       -3.35985771e-03, -3.02240187e-05, -2.12348555e-03,  2.86724488e-03,\n",
              "       -2.91198958e-03, -2.91085127e-03, -5.50444587e-04, -1.72330614e-03,\n",
              "        2.32299106e-04,  5.16094966e-04, -3.83294566e-04,  4.76076640e-03,\n",
              "       -4.44446784e-03, -1.75583863e-03,  2.84307782e-04,  1.54030378e-04,\n",
              "       -6.21339539e-04,  8.51287987e-05, -4.86089120e-05,  1.84070843e-03,\n",
              "        1.72342139e-03,  2.93154945e-03,  1.17985730e-03,  2.01370241e-03,\n",
              "       -2.21741945e-03,  1.22255494e-03, -3.88861750e-04, -1.35775271e-03,\n",
              "        2.50758021e-03, -2.39759684e-03, -3.52050731e-04, -4.25555278e-03,\n",
              "        8.25439056e-04,  3.99412354e-04,  1.96636142e-03,  4.33731917e-03,\n",
              "       -1.11827485e-05,  4.63782251e-03,  4.26271791e-03,  6.48353191e-04,\n",
              "        3.32296477e-03,  2.08460516e-03, -1.12440065e-03, -4.92068473e-03,\n",
              "       -2.82706181e-03, -6.82074286e-04, -3.76637815e-03, -4.37785406e-03,\n",
              "       -3.52343661e-03,  4.98656416e-03, -2.88638799e-03, -2.52696639e-03,\n",
              "        4.26976755e-03,  3.66484490e-03, -2.46587140e-03, -2.71279714e-03,\n",
              "        1.60979340e-03, -5.39043220e-04, -7.60775874e-04, -4.30499949e-03,\n",
              "        2.65319622e-03, -4.58870735e-03,  3.75179283e-04,  3.48002021e-03,\n",
              "        1.49094255e-03,  3.92905856e-03,  2.82303570e-03, -1.52954634e-03,\n",
              "        1.37482959e-04,  1.46762887e-03,  1.66353432e-03, -3.76667682e-04,\n",
              "       -7.25517864e-04,  4.40559303e-03,  3.93416965e-03, -7.85015291e-04,\n",
              "        2.92079477e-03,  4.86226846e-03, -1.78280612e-03, -2.75881542e-03],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5tpDEcjdB3i",
        "colab_type": "code",
        "outputId": "15a66fa9-be4b-4e09-8a16-dd900571cdaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        }
      },
      "source": [
        "# Look at document vector\n",
        "model[2]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-4.38587973e-03, -3.57072474e-03,  3.88431968e-03, -3.47585743e-03,\n",
              "        4.75853402e-03,  2.79352395e-03,  1.26587390e-03, -3.00626713e-03,\n",
              "        3.41877574e-03, -4.91604907e-03, -2.69041071e-03,  3.25385598e-03,\n",
              "        3.46013950e-03, -5.85328904e-04, -3.93068977e-03, -4.48601600e-03,\n",
              "        3.22551560e-03, -3.64639168e-03, -2.90193758e-03,  4.85022413e-03,\n",
              "        3.61483335e-03,  6.08189090e-04, -3.75569012e-04,  1.58393080e-03,\n",
              "       -2.18574191e-03,  4.77644242e-03, -1.14011962e-03, -3.77471698e-03,\n",
              "        3.03882430e-03,  3.97146167e-03,  1.23964564e-03,  2.08758726e-03,\n",
              "        4.11385344e-03, -5.96546393e-04, -8.63870548e-04, -3.46013415e-03,\n",
              "       -3.88592342e-03,  2.72085005e-03, -3.88643844e-03,  1.16048905e-04,\n",
              "       -3.56198126e-03, -3.09477118e-03, -4.99721849e-03,  3.15565430e-03,\n",
              "       -1.67173077e-03, -4.89549898e-03,  4.84334212e-03,  4.26977361e-03,\n",
              "        4.39984491e-03, -3.46464664e-03, -1.88309746e-03,  9.30987007e-04,\n",
              "        4.11939668e-03, -4.47148178e-03,  1.18756422e-03,  3.87846655e-03,\n",
              "        2.58137379e-03,  1.14759174e-03, -7.68443104e-04, -2.41491687e-03,\n",
              "        3.09955189e-03,  3.30742623e-05,  6.68460387e-04, -3.38823837e-03,\n",
              "        6.08071859e-05,  2.62312079e-03,  4.90050297e-04, -3.37311678e-04,\n",
              "        1.15552184e-03,  8.50248092e-04, -2.70760106e-03,  1.49491744e-03,\n",
              "        2.45209644e-03,  2.18207389e-03,  2.59493780e-03, -1.31361699e-03,\n",
              "        3.06358631e-03, -1.11899211e-03, -4.04881127e-03,  3.55698029e-03,\n",
              "       -1.71746372e-03, -2.77124665e-04,  3.98012437e-03, -9.18136269e-04,\n",
              "        4.21431242e-03, -4.29446762e-03, -2.40897713e-03,  3.26622423e-04,\n",
              "        2.25612265e-03, -2.80450191e-03, -2.30100169e-03,  7.55615998e-04,\n",
              "        2.73061474e-03,  2.19722767e-03, -3.22724413e-03, -4.50298144e-03,\n",
              "        6.11135445e-04,  4.99214325e-03,  7.24923972e-04,  1.51428953e-03],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F65Ruqq4dB3w",
        "colab_type": "code",
        "outputId": "a93df399-c895-4349-b744-3c3863799203",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Calculate the Euclidean distance between document vectors\n",
        "np.linalg.norm(model[0]-model[1]), np.linalg.norm(model[0]-model[2]), np.linalg.norm(model[1]-model[2])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.036447875, 0.036241837, 0.041457236)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VX39TCLdB4B",
        "colab_type": "code",
        "outputId": "ab270ad1-5a2d-42f7-d227-a460491b05ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Calculate cosine similarities between document vectors\n",
        "cos_similarity0=np.dot(model[0],model[1]) / (np.linalg.norm(model[0])*np.linalg.norm(model[1]))\n",
        "cos_similarity1=np.dot(model[0],model[2]) / (np.linalg.norm(model[0])*np.linalg.norm(model[2]))\n",
        "cos_similarity2=np.dot(model[1],model[2]) / (np.linalg.norm(model[1])*np.linalg.norm(model[2]))\n",
        "cos_similarity0,cos_similarity1,cos_similarity2\n",
        "# They are all rather different"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.04435811, 0.16789521, -0.07092797)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pW-5lGK1dB4P",
        "colab_type": "code",
        "outputId": "29178dc2-103d-47cf-9d88-2f7e73b36ba8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Calculate cosine distances between document vectors\n",
        "1-cos_similarity0,1-cos_similarity1,1-cos_similarity2\n",
        "# Shortest distance is between doc0 and doc2."
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9556418918073177, 0.8321047872304916, 1.07092797011137)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJQYi0b3dB4i",
        "colab_type": "text"
      },
      "source": [
        "## 2A) Load the FastText model from Facebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dh06xUOdB4l",
        "colab_type": "text"
      },
      "source": [
        "There are different language versions\n",
        "\n",
        "How it works is very similar to Google's Word2Vec model.\n",
        "- download the bin+text model for your language of choice to your local MODEL_PATH\n",
        "- unzip the binary language file (note: en.wiki.zip file is 9.6GB)\n",
        "- then with following script, load it into gensim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsJhbrbqdB4q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from gensim.models.fasttext import FastText\n",
        "# ft_model=FastText.load_fasttext_format(model_file=MODEL_PATH)\n",
        "# ft_model.most_similar('soccer')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqlGFvyrdB47",
        "colab_type": "text"
      },
      "source": [
        "## 3A) GloVe (Global Vectors from Stanford)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1Rxws4SdB5B",
        "colab_type": "text"
      },
      "source": [
        "Stanford GloVe project: https://nlp.stanford.edu/projects/glove/\n",
        "- publication: Global Vectors for Word representation: https://nlp.stanford.edu/pubs/glove.pdf\n",
        "- method : SVD singular value decomposition of word co-occurrence matrix, splitting it into two weight matrices that Word2Vec produces\n",
        "- the key was to normalize the co-occurrence matrix the same way. \n",
        "- sometimes Word2Vec was not able to converge to global optimum, while GloVe did.\n",
        "\n",
        "Thus the main idea in GloVe is direct optimization of global vectors of word co-occurrences (across the entire corpus), which gives it its name.\n",
        "- Word2Vectors relies on backpropagation to update the weights, which is less efficient.\n",
        "\n",
        "Thus it is recommended nowadays to use GloVe to train new word vector representations.\n",
        "- faster training, better RAM/CPU efficiency\n",
        "- more efficient use of data (better for smaller corpora)\n",
        "- more accurate for the same amount of training."
      ]
    }
  ]
}